#!/usr/bin/env ruby

require 'fileutils'
require 'uri'
require 'net/http'

if ENV['FLY_APP_NAME']
  # ensure machine is the only one in its region
  machines_by_region = `dig +short txt _instances.internal`.
    chomp.gsub('" "', '').gsub('"', '').split(';').
    map {|instance| instance.scan(/(\w+)=([^,]+)/).to_h}.
    select {|instance| instance['app'] == ENV["FLY_APP_NAME"]}.
    reject {|instance| instance['instance'] == ENV["FLY_ALLOC_ID"]}.
    sort_by {|instance| instance['instance']}.
    map {|instance| [instance['instance'], instance['region']]}.
    sort_by(&:first).group_by(&:last).
    map {|region, instances| [region, instances.first.first]}.to_h

  if machines_by_region.values.include? ENV["FLY_ALLOC_ID"]
    STDERR.puts "Another machine exists in this region, exiting"
    exit 1
  end

  # show maintenance mode
  system "nginx -c /rails/config/nginx.startup"

  # start rsync daemon
  system "rsync --daemon"

  # setup volume, .ssh, db, storage, log directories
  VOLUME = File.dirname(ENV.fetch('RAILS_DB_VOLUME', '/data/db'))
  FileUtils.chown('rails', 'rails', VOLUME)
  FileUtils.mkdir_p "#{VOLUME}/.ssh"
  FileUtils.mkdir_p ENV['RAILS_DB_VOLUME']
  FileUtils.mkdir_p ENV['RAILS_STORAGE']

  # Create log directory and fix ownership if it exists but is owned by root
  if ENV['RAILS_LOG_VOLUME']
    FileUtils.mkdir_p ENV['RAILS_LOG_VOLUME']

    # Fix ownership if directory exists but is owned by root (migration fix)
    if File.exist?(ENV['RAILS_LOG_VOLUME'])
      stat = File.stat(ENV['RAILS_LOG_VOLUME'])
      if stat.uid == 0  # owned by root
        STDERR.puts "Fixing ownership of #{ENV['RAILS_LOG_VOLUME']} (currently owned by root)"
      end
    end
  end

  # change ownership of data files
  FileUtils.chown_R 'rails', 'rails', [
    ENV['RAILS_DB_VOLUME'],
    ENV['RAILS_STORAGE'],
    ENV['RAILS_LOG_VOLUME']
  ].compact

  # openssh: fly environment variables
  IO.write '/etc/environment',
    ENV.select{|key, value| key =~ /^FLY_*|PRIMARY_REGION/}.
    map {|key, value| "#{key}=#{value}\n"}.join

  # openssh: install authorized key and host keys
  Dir.chdir "#{VOLUME}/.ssh" do
    # install authorized key to allow ssh in
    if File.exist? "authorized_keys"
      if not Dir.exist? "/home/rails/.ssh"
        FileUtils.mkdir_p "/home/rails/.ssh"
        FileUtils.chmod 0700, "/home/rails/.ssh"
        FileUtils.chown "rails", "rails", "/home/rails/.ssh"
      end

      if not File.exist? "/home/rails/.ssh/authorized_keys"
        FileUtils.cp "authorized_keys", "/home/rails/.ssh/authorized_keys"
        FileUtils.chown "rails", "rails", "/home/rails/.ssh/authorized_keys"
      end
    end

    # ensure host keys remain stable
    host_keys = Dir['ssh_host*']
    if host_keys.empty?
      # generate new keys
      Dir["/etc/ssh/ssh_host*.key"].each do key
        type = key[/.*_(\w+)_key/, 1]
        FileUtils.rm [key, "{key}.pub"]
        system "ssh-keygen -q -N '' -t #{type} -f #{key}"
      end

      # save keys on volume
      FileUtils.cp Dir["/etc/ssh/ssh_host*"], Dir.pwd
    else
      # restore keys from volume
      host_keys.each do |key|
        if File.read(key) != File.read("/etc/ssh/#{key}")
          FileUtils.cp key, "/etc/ssh/#{key}", preserve: true
        end
      end
    end
  end

  # start ssyd
  system "/usr/sbin/sshd"

  # Sync data from primary region
  if ENV['FLY_REGION'] != ENV['PRIMARY_REGION']
    source = "rsync://#{ENV['PRIMARY_REGION']}.#{ENV['FLY_APP_NAME']}.internal"
  elsif !Dir.exist?("#{VOLUME}/db/") and !machines_by_region.empty?
    # new machine in primary region, pick a random region to sync from
    source = "rsync://#{machines_by_region.keys.sample}.#{ENV['FLY_APP_NAME']}.internal"
  else
    source = nil
  end

  if File.executable? '/usr/local/bin/rclone'
    config = "#{Dir.home}/.config/rclone/rclone.conf"
    FileUtils.mkdir_p File.dirname(config)
    File.write config, <<~CONFIG unless File.exist? config
      [tigris]
      type = s3
      provider = AWS
      endpoint = https://fly.storage.tigris.dev
      access_key_id = #{ENV['AWS_ACCESS_KEY_ID']}
      secret_access_key = #{ENV['AWS_SECRET_ACCESS_KEY']}
    CONFIG
    #
    # Migration notes:
    # cp -p /data/storage/2023-*/*/*/* .
    # rclone sync --progress . tigris:showcase
    # ActiveStorage::Blob.update_all(service_name: 'tigris')
  end

  if source
    # get authorized keys
    authkeys = "#{VOLUME}/.ssh/authorized_keys"
    if not File.exist? authkeys
      system *%W(
        rsync
        -av
        #{source}/ssh/authorized_keys
        #{authkeys}
      )
    end

    # synch databases
    system *%W(
      rsync
      -av
      --update
      #{source}#{VOLUME}/db
      #{VOLUME}
    )
  end

  LATEST = Dir["#{VOLUME}/db/2*.sqlite3"].map {|name| File.mtime(name) rescue Time.at(0)}.max
elsif not ENV['FLY_REGION']
  FileUtils.cp 'config/storage/development.yml', 'config/storage/production.yml'
end

# set up nginx and run migrations
Dir.chdir File.dirname(__dir__) do
  system "#{RbConfig.ruby} ./config/tenant/nginx-config.rb"

  showcase_conf = '/etc/nginx/sites-enabled/showcase.conf'
  if IO.read(showcase_conf).include? '410'
    fork do
      10.times do
        sleep 30
        STDERR.puts "Reconfiguring nginx..."
        system "#{RbConfig.ruby} ./config/tenant/nginx-config.rb"
        exit unless IO.read(showcase_conf).include? '410'
      end
    end
  end
end

# Sync databases back to primary region
if ENV['FLY_APP_NAME']
  if Dir["#{VOLUME}/db/2*.sqlite3"].map {|name| File.mtime(name) rescue Time.at(0)}.max > LATEST
    if ENV['FLY_REGION'] != ENV['PRIMARY_REGION']
      dest = "rsync://#{ENV['PRIMARY_REGION']}.#{ENV['FLY_APP_NAME']}.internal"

      # synch databases
      system *%W(
        rsync
        -av
        --update
        --exclude .time
        #{VOLUME}/db/
        #{dest}#{VOLUME}/db/
      )
    end

    # sync databases to S3
    system "script/sync_databases_s3.rb --safe"

    # run webhook
    uri = URI('https://rubix.intertwingly.net/webhook/showcase')
    res = Net::HTTP.get_response(uri)
    if res.is_a?(Net::HTTPSuccess)
      puts res.body
    else
      STDERR.puts res
      STDERR.puts res.body
    end
  end

  # Configure memory for redis
  # https://redis.io/docs/getting-started/faq/#background-saving-fails-with-a-fork-error-on-linux
  File.write '/proc/sys/vm/overcommit_memory', '1'

  # exit maintenance mode
  system "nginx -c /rails/config/nginx.startup -s stop"
end
